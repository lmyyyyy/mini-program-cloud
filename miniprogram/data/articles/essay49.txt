DAVID VOGT’S son loves Lego. As they played together one day, the robotics professor had an idea: could he teach a robot to put the blocks together? 
“We thought it would be funny to make a robot that could do the same thing I am doing with my son,” says Vogt, who is at the Freiberg University of Mining and Technology in Germany. 
So Vogt and his colleagues brought an industrial robot arm to the lab. Like a child playing for the first time, the robot – equipped with a Kinect depth camera – observed two experienced humans wearing motion tracking tags as they built a Lego rocket. After just one session, the robot was able to partner with a human to build the rocket. It could also cope with some blocks not being exactly where it expected to find them. 
The project, to be presented next month at the International Conference on Humanoid Robots in Cancun, Mexico, is one of several recent examples of teaching robots through human demonstration. 
Humans learn how to do lots of things by watching someone else, but programming a new skill into robots is difficult, says Aude Billard at the Swiss Federal Institute of Technology in Lausanne. We know intuitively how to do certain tasks, but struggle to express that knowledge as programming. 
Instead, engineers have found ways to show robots what to do, rather than tell them. Some remotely control the robot through its first few tries, getting a sense of its experience using the buzz of haptic feedback. And last year, a robot at the University of Maryland started learning to cook by watching YouTube videos of people in the kitchen. 
“A good teacher will understand that the robot has different ways of perceiving the world“ 
In work published earlier this month, researchers at Google took a hands-on approach, teaching a robot how to open a door by physically guiding it through each step. Later the robot tried on its own, starting with a similar door. It was then able to apply what it had learned to open doors even when their orientation was different to what it had encountered before. 
“We have a lot of intuition about how various manipulation skills can be performed, and it only seems natural that transferring this intuition to robots can help them learn these skills a lot faster,” the Google researchers wrote. 
Another trick is to make sure the data is translated in a way that makes sense for that particular robot. Most robots don’t have structures or sensors that mirror the human anatomy, for example. “Part of being a good teacher is understanding that the device that you’re teaching has different ways of acting in the world and different ways of perceiving it,” says Billard. 
Vogt’s team thinks that learning through human demonstrations will make robots better able to assist humans with skilled factory work. This could mean having the right tool ready when a worker needs it or stepping in to perform some tasks on its own. That could relieve some of the physical stress on workers, says team member Heni Ben Amor at Arizona State University in Tempe. 
“Ideally, humans and robots together should be able to do something that, individually or separately, they wouldn’t have been able to do alone,” he says. 